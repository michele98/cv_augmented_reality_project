{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from utils.matchers import FeatureMatcher, MultipleInstanceMatcher\n",
    "from utils.visualization import display_frames, display_ar_frames\n",
    "from utils.utils import save_ar_video_f2r, save_ar_video_f2f, save_ar_video\n",
    "\n",
    "#reloads external modules when they are changed\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_filename = './Data/Multiple View.avi'\n",
    "\n",
    "reference_frame = cv2.cvtColor(cv2.imread('Data/ReferenceFrame.png', cv2.IMREAD_COLOR), cv2.COLOR_BGR2RGB)\n",
    "reference_mask = cv2.imread('Data/ObjectMask.PNG', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "ar_layer = cv2.cvtColor(cv2.imread('Data/AugmentedLayer.PNG', cv2.IMREAD_COLOR), cv2.COLOR_BGR2RGB)[:,:640]\n",
    "ar_mask = cv2.imread('Data/AugmentedLayerMask.PNG', cv2.IMREAD_GRAYSCALE)[:,:640]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w, h, dpi = 1000, 500, 100\n",
    "fig, ax = plt.subplots(ncols=2, figsize=(w/dpi, h/dpi), dpi=dpi)\n",
    "\n",
    "ax[0].imshow(reference_frame)\n",
    "ax[0].set_title('Reference frame')\n",
    "\n",
    "ax[1].imshow(reference_mask, cmap='gray')\n",
    "ax[1].set_title('Mask')\n",
    "\n",
    "fig.tight_layout(pad=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AR layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w, h, dpi = 1000, 500, 100\n",
    "fig, ax = plt.subplots(ncols=2, figsize=(w/dpi, h/dpi), dpi=dpi)\n",
    "\n",
    "ax[0].imshow(ar_layer)\n",
    "ax[0].set_title('AR layer')\n",
    "\n",
    "ax[1].imshow(ar_mask, cmap='gray')\n",
    "ax[1].set_title('Mask')\n",
    "\n",
    "fig.tight_layout(pad=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_frames(video_filename, starting_frame=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stitch AR layer onto reference frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar_frame = reference_frame.copy()\n",
    "ar_frame[ar_mask==255] = ar_layer[ar_mask==255]\n",
    "\n",
    "w, h, dpi = 1200, 400, 100\n",
    "fig, ax = plt.subplots(ncols=3, figsize=(w/dpi, h/dpi), dpi=dpi)\n",
    "\n",
    "ax[0].imshow(reference_frame)\n",
    "ax[0].set_title('Reference frame')\n",
    "\n",
    "ax[1].imshow(ar_layer)\n",
    "ax[1].set_title('AR layer')\n",
    "\n",
    "ax[2].imshow(ar_frame)\n",
    "ax[2].set_title('Combination')\n",
    "\n",
    "fig.tight_layout(pad=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do AR on the video\n",
    "Overlay the AR layer onto the video frame.\n",
    "\n",
    "At the beginning, the AR layer and a reference image onto which the AR layer should be stitched are needed.\n",
    "\n",
    "Then the homography between the reference image and the video frame is computed, and it is then applied to the AR layer.\n",
    "\n",
    "The homography between the reference image and the video frames is found using local invariant features, which are found using SIFT. The matches between the SIFT descriptors are then found using FLANN KDTree, and finally the homography is computed\n",
    "on the resulting matches using RANSAC.\n",
    "\n",
    "All this is implemented in the ``matchers.FeatureMatcher`` class.\n",
    "\n",
    "Both the F2R (frame to reference) and F2F (frame to frame) have been tried. The results show that F2F produces a smoother result, but the AR layer drifts over time due to the accumulation of errors.\n",
    "\n",
    "In F2F, the AR layer stays consistently in the right place, but the AR layer appears to be stuttering sometimes.\n",
    "It was also tried to reset the reference frame after a certain number of frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_filename = './Data/Multiple View.avi'\n",
    "\n",
    "reference_frame = cv2.cvtColor(cv2.imread('Data/ReferenceFrame.png', cv2.IMREAD_COLOR), cv2.COLOR_BGR2RGB)\n",
    "reference_mask = cv2.imread('Data/ObjectMask.PNG', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "ar_layer = cv2.cvtColor(cv2.imread('Data/AugmentedLayer.PNG', cv2.IMREAD_COLOR), cv2.COLOR_BGR2RGB)[:,:640]\n",
    "ar_mask = cv2.imread('Data/AugmentedLayerMask.PNG', cv2.IMREAD_GRAYSCALE)[:,:640]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F2R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_ar_video_f2r(video_filename,\n",
    "                  'out_f2r.avi',\n",
    "                  ar_layer=ar_layer,\n",
    "                  ar_mask=ar_mask,\n",
    "                  reference_image=reference_frame,\n",
    "                  reference_mask=reference_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F2F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_ar_video_f2f(video_filename,\n",
    "                  'out_f2f.avi',\n",
    "                  ar_layer=ar_layer,\n",
    "                  ar_mask=ar_mask,\n",
    "                  reference_image=reference_frame,\n",
    "                  reference_mask=reference_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F2F with reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = 30\n",
    "save_ar_video(video_filename,\n",
    "              f'out_h{r}.avi',\n",
    "              ar_layer=ar_layer,\n",
    "              ar_mask=ar_mask,\n",
    "              reference_image=reference_frame,\n",
    "              reference_mask=reference_mask,\n",
    "              drift_correction_step=r)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('cv_product_recognition')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b330a1fc137f30f9ef94b968cb21ea387197e87b19802386bf07bfb3ddcfdd68"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
